{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Script and Subtitle Scraper for Movies**\n",
        "\n",
        "### Main Goals:\n",
        "1. **Scrape Movie Scripts**: Retrieve scripts from IMSDB, Springfield Springfield, and MovieScripts.com for given movie titles.\n",
        "2. **Scrape Subtitles**: Download and process subtitles from OpenSubtitles and YTS Subtitles.\n",
        "3. **Process Movie Titles in Chunks**: Handle large lists of movie titles (e.g., from CSV files) in manageable chunks.\n",
        "4. **Save Results**: Store retrieved scripts and subtitles in separate CSV files for easy reference and analysis."
      ],
      "metadata": {
        "id": "XYaf4qRdWAAC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTXZp_td6VXC",
        "outputId": "1eb77019-5edb-42ab-8389-f4c6c2cdcbac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 2 (from 10,001 to 20,000) completed and saved to 'top_movies_scripts_and_subtitles.csv'.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import zipfile\n",
        "import io\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "# 1. IMSDB Scraper: Scrapes movie scripts from IMSDB.\n",
        "def scrape_imsdb_script(movie_title):\n",
        "    \"\"\"Scrape the script from IMSDB for a given movie.\"\"\"\n",
        "    formatted_title = movie_title.replace(\" \", \"-\")\n",
        "    url = f\"https://imsdb.com/scripts/{formatted_title}.html\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            script_div = soup.find('pre')\n",
        "            if script_div and script_div.get_text(strip=True):\n",
        "                return script_div.get_text(strip=True)\n",
        "        return f\"Script not found on IMSDB for '{movie_title}'.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching script from IMSDB: {e}\"\n",
        "\n",
        "\n",
        "# 2. Springfield Scraper: Scrapes movie scripts from Springfield! website.\n",
        "def scrape_springfields_script(movie_title):\n",
        "    \"\"\"Scrape the script from Springfield! website.\"\"\"\n",
        "    formatted_title = movie_title.replace(\" \", \"-\")\n",
        "    url = f\"https://www.springfieldspringfield.co.uk/movie_script.php?movie={formatted_title}\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            script_div = soup.find('div', class_='scrolling-script-container')\n",
        "            if script_div and script_div.get_text(strip=True):\n",
        "                return script_div.get_text(strip=True)\n",
        "        return f\"Script not found on Springfield for '{movie_title}'.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching script from Springfield: {e}\"\n",
        "\n",
        "\n",
        "# 3. OpenSubtitles Scraper: Scrapes subtitles from OpenSubtitles.org.\n",
        "def scrape_opensubtitles(movie_title):\n",
        "    \"\"\"Download and return the subtitle text from OpenSubtitles.\"\"\"\n",
        "    search_url = f\"https://www.opensubtitles.org/en/search2/sublanguageid-eng/moviename-{movie_title.replace(' ', '+')}\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(search_url, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            first_result = soup.find('a', class_='bnone')\n",
        "            if first_result:\n",
        "                subtitle_page_link = \"https://www.opensubtitles.org\" + first_result['href']\n",
        "                return download_and_extract_subtitle(subtitle_page_link, movie_title)\n",
        "        return f\"Subtitle not found on OpenSubtitles for '{movie_title}'.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching subtitle from OpenSubtitles: {e}\"\n",
        "\n",
        "\n",
        "def download_and_extract_subtitle(file_url, movie_title):\n",
        "    \"\"\"Download and process a subtitle file.\"\"\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    try:\n",
        "        response = requests.get(file_url, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            content_type = response.headers.get('Content-Type', '')\n",
        "            subtitle_file_name = f\"{movie_title}.srt\"\n",
        "            if 'application/zip' in content_type or zipfile.is_zipfile(io.BytesIO(response.content)):\n",
        "                with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "                    srt_files = [file for file in z.namelist() if file.endswith('.srt')]\n",
        "                    if srt_files:\n",
        "                        with z.open(srt_files[0]) as extracted_file:\n",
        "                            with open(subtitle_file_name, 'wb') as f:\n",
        "                                f.write(extracted_file.read())\n",
        "                        return f\"Subtitle extracted for '{movie_title}'.\"\n",
        "            else:\n",
        "                with open(subtitle_file_name, 'wb') as f:\n",
        "                    f.write(response.content)\n",
        "                return f\"Subtitle downloaded for '{movie_title}'.\"\n",
        "        return \"Failed to download subtitle file.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error downloading subtitle: {e}\"\n",
        "\n",
        "\n",
        "# 4. Chunk Processing: Processes a list of movies and scrapes data in chunks.\n",
        "def process_movies_in_chunks(input_file):\n",
        "    \"\"\"Process movies in chunks, scraping scripts and subtitles.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(input_file)\n",
        "        if 'Movie Name' not in df.columns:\n",
        "            return \"Error: 'Movie Name' column not found in the CSV file.\"\n",
        "\n",
        "        chunk_size = 10000\n",
        "        for chunk_num, chunk in enumerate(range(0, len(df), chunk_size)):\n",
        "            results = []\n",
        "            for _, row in df.iloc[chunk:chunk + chunk_size].iterrows():\n",
        "                movie_title = row['Movie Name']\n",
        "                script_imsdb = scrape_imsdb_script(movie_title)\n",
        "                script_springfield = scrape_springfields_script(movie_title)\n",
        "                subtitle = scrape_opensubtitles(movie_title)\n",
        "\n",
        "                results.append({\n",
        "                    'Movie Name': movie_title,\n",
        "                    'Script_IMSDB': script_imsdb,\n",
        "                    'Script_Springfield': script_springfield,\n",
        "                    'Subtitle': subtitle\n",
        "                })\n",
        "\n",
        "            chunk_df = pd.DataFrame(results)\n",
        "            chunk_file_name = f\"chunk_{chunk_num + 1}.csv\"\n",
        "            chunk_df.to_csv(chunk_file_name, index=False)\n",
        "    except Exception as e:\n",
        "        return f\"Error processing movies: {e}\"\n",
        "\n",
        "\n",
        "input_file = \"movies_names.csv\"\n",
        "process_movies_in_chunks(input_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Script and Subtitle Availability Analysis and Filtering**\n",
        "\n",
        "### Main Goals:\n",
        "1. **Categorize Script Availability**: The function `categorize_script_availability` checks if a movie's script or subtitle is available or not, based on certain text markers like \"not available\" or \"Failed to download\".\n",
        "2. **Count Availability**: It calculates and prints the count of available and unavailable scripts/subtitles.\n",
        "3. **Identify Movies Without Scripts**: It determines how many movies don't have a script or subtitle available.\n",
        "4. **Handle Null Values**: It checks for and prints any null values in the dataset.\n",
        "5. **Filter and Save Data**: It filters out rows with unavailable scripts/subtitles and saves the cleaned data into a new CSV file (`filtered_movies.csv`).\n",
        "6. **Load and Process Data**: Reads the movie script and subtitle data, assigns appropriate column names, filters, and saves results for further use.\n",
        "\n",
        "### Key Sections of the Code:\n",
        "- **`categorize_script_availability`** function: Categorizes whether scripts/subtitles are available.\n",
        "- **DataFrame cleaning and filtering**: Filters out rows with specific unavailability markers and saves the filtered data."
      ],
      "metadata": {
        "id": "APDk_-SiWvqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the data\n",
        "scripts = pd.read_csv('/content/top_movies_scripts_and_subtitles.csv', sep=';')\n",
        "\n",
        "# Step 2: Define the categorization function for script availability\n",
        "def categorize_script_availability(text):\n",
        "    if \"not available\" in text or \"Failed to download\" in text:\n",
        "        return \"Not Available\"\n",
        "    else:\n",
        "        return \"Available\"\n",
        "\n",
        "# Step 3: Apply the function to categorize the availability of scripts/subtitles\n",
        "scripts['Availability'] = scripts['Script/Subtitle Text'].apply(categorize_script_availability)\n",
        "\n",
        "# Step 4: Count and display the availability of scripts\n",
        "availability_count = scripts['Availability'].value_counts()\n",
        "print(\"\\nScript Availability Count:\")\n",
        "print(availability_count)\n",
        "\n",
        "# Step 5: Count the number of movies without scripts/subtitles available\n",
        "num_movies_without_scripts = scripts[scripts['Availability'] == 'Not Available'].shape[0]\n",
        "print(f\"\\nNumber of movies without scripts: {num_movies_without_scripts}\")\n",
        "\n",
        "# Step 6: Check for NULL values in the dataset\n",
        "null_values = scripts.isnull().sum()\n",
        "print(\"\\nNULL Values in Each Column:\")\n",
        "print(null_values)\n",
        "\n",
        "# Step 7: Create a DataFrame\n",
        "df = pd.DataFrame(scripts)\n",
        "\n",
        "# Step 8: Filter out rows where 'Script/Subtitle Text' contains 'Script not available on Springfield'\n",
        "filtered_df = df[df['Script/Subtitle Text'] != 'Script not available on Springfield']\n",
        "\n",
        "# Step 9: Display the filtered DataFrame and save it to a new CSV file\n",
        "print(filtered_df)\n",
        "filtered_df.to_csv('filtered_movies.csv', index=False)\n",
        "print(\"Filtered data saved to 'filtered_movies.csv'\")\n",
        "\n",
        "# Step 10: Load the data again (with no header) for further processing\n",
        "dataa = pd.read_csv('/content/top_movies_scripts_and_subtitles.csv', sep=';')\n",
        "df = pd.read_csv('/content/top_movies_scripts_and_subtitles.csv', sep=';', header=None)\n",
        "\n",
        "# Step 11: Assign appropriate column names to the DataFrame\n",
        "df.columns = ['Movie Name', 'Script/Subtitle Text']\n",
        "\n",
        "# Step 12: Display the DataFrame\n",
        "print(df)\n",
        "\n",
        "# Step 13: Update column names to include 'Availability'\n",
        "df.columns = ['Movie Name', 'Script/Subtitle Text', 'Availability']\n",
        "\n",
        "# Step 14: Drop rows where 'Availability' is 'Not Available'\n",
        "df_filtered = df[df['Availability'] != 'Not Available']\n",
        "\n",
        "# Step 15: Display the filtered DataFrame and save it to a new CSV file\n",
        "print(df_filtered)\n",
        "df_filtered.to_csv('filtered_data.csv', index=False)\n",
        "print(\"Filtered data saved to 'filtered_data.csv'\")"
      ],
      "metadata": {
        "id": "gt-y20eXWxDZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}